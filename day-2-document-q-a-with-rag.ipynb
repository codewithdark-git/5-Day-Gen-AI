{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0beabdf",
   "metadata": {
    "id": "Tce3stUlHN0L",
    "papermill": {
     "duration": 0.0107,
     "end_time": "2024-11-13T11:07:49.919000",
     "exception": false,
     "start_time": "2024-11-13T11:07:49.908300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Copyright 2024 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1203e538",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-11-13T11:07:49.938896Z",
     "iopub.status.busy": "2024-11-13T11:07:49.938345Z",
     "iopub.status.idle": "2024-11-13T11:07:49.944558Z",
     "shell.execute_reply": "2024-11-13T11:07:49.943489Z"
    },
    "id": "tuOe1ymfHZPu",
    "papermill": {
     "duration": 0.018848,
     "end_time": "2024-11-13T11:07:49.946968",
     "exception": false,
     "start_time": "2024-11-13T11:07:49.928120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfbeb48",
   "metadata": {
    "id": "CsVPnR8VbXE6",
    "papermill": {
     "duration": 0.008711,
     "end_time": "2024-11-13T11:07:49.964503",
     "exception": false,
     "start_time": "2024-11-13T11:07:49.955792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Day 2 - Document Q&A with RAG using Chroma\n",
    "\n",
    "Welcome back to the Kaggle 5-day Generative AI course!\n",
    "\n",
    "**NOTE**: The Day 1 notebook contains lots of information for getting set up with Kaggle Notebooks. If you are having any issues, please [check out the troubleshooting steps there](https://www.kaggle.com/code/markishere/day-1-prompting#Get-started-with-Kaggle-notebooks).\n",
    "\n",
    "Two big limitations of LLMs are 1) that they only \"know\" the information that they were trained on, and 2) that they have limited input context windows. A way to address both of these limitations is to use a technique called Retrieval Augmented Generation, or RAG. A RAG system has three stages:\n",
    "\n",
    "1. Indexing\n",
    "2. Retrieval\n",
    "3. Generation\n",
    "\n",
    "Indexing happens ahead of time, and allows you to quickly look up relevant information at query-time. When a query comes in, you retrieve relevant documents, combine them with your instructions and the user's query, and have the LLM generate a tailored answer in natural language using the supplied information. This allows you to provide information that the model hasn't seen before, such as product-specific knowledge or live weather updates.\n",
    "\n",
    "In this notebook you will use the Gemini API to create a vector database, retrieve answers to questions from the database and generate a final answer. You will use [Chroma](https://docs.trychroma.com/), an open-source vector database. With Chroma, you can store embeddings alongside metadata, embed documents and queries, and search your documents.\n",
    "\n",
    "## For help\n",
    "\n",
    "**Common issues are covered in the [FAQ and troubleshooting guide](https://www.kaggle.com/code/markishere/day-0-troubleshooting-and-faqs).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561f4e2",
   "metadata": {
    "id": "akuOzK4dJl3j",
    "papermill": {
     "duration": 0.008529,
     "end_time": "2024-11-13T11:07:49.982092",
     "exception": false,
     "start_time": "2024-11-13T11:07:49.973563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, install ChromaDB and the Gemini API Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98fb827b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:07:50.002568Z",
     "iopub.status.busy": "2024-11-13T11:07:50.002144Z",
     "iopub.status.idle": "2024-11-13T11:08:48.752423Z",
     "shell.execute_reply": "2024-11-13T11:08:48.750999Z"
    },
    "id": "JbXe7Oodc5dP",
    "papermill": {
     "duration": 58.763022,
     "end_time": "2024-11-13T11:08:48.755046",
     "exception": false,
     "start_time": "2024-11-13T11:07:49.992024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 31.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q \"google-generativeai>=0.8.3\" chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b3fe31",
   "metadata": {
    "papermill": {
     "duration": 0.009094,
     "end_time": "2024-11-13T11:08:48.773385",
     "exception": false,
     "start_time": "2024-11-13T11:08:48.764291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You may see output containing `ERROR: pip's dependency resolver does not currently take into account all the packages that are installed` - this is OK, the packages are still installed and compatible for this codelab. Also note that you do not have to restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dda0ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:08:48.794747Z",
     "iopub.status.busy": "2024-11-13T11:08:48.793661Z",
     "iopub.status.idle": "2024-11-13T11:08:49.969220Z",
     "shell.execute_reply": "2024-11-13T11:08:49.968057Z"
    },
    "id": "muuhsDmmKdHi",
    "papermill": {
     "duration": 1.189431,
     "end_time": "2024-11-13T11:08:49.971879",
     "exception": false,
     "start_time": "2024-11-13T11:08:48.782448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f11c36",
   "metadata": {
    "id": "FQOGMejVu-6D",
    "papermill": {
     "duration": 0.009158,
     "end_time": "2024-11-13T11:08:49.990936",
     "exception": false,
     "start_time": "2024-11-13T11:08:49.981778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Set up your API key\n",
    "\n",
    "To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
    "\n",
    "If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
    "\n",
    "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0924bb8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:08:50.012193Z",
     "iopub.status.busy": "2024-11-13T11:08:50.011357Z",
     "iopub.status.idle": "2024-11-13T11:08:50.881686Z",
     "shell.execute_reply": "2024-11-13T11:08:50.880722Z"
    },
    "id": "ysayz8skEfBW",
    "papermill": {
     "duration": 0.884074,
     "end_time": "2024-11-13T11:08:50.884507",
     "exception": false,
     "start_time": "2024-11-13T11:08:50.000433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36413c2e",
   "metadata": {
    "id": "52b101760a45",
    "papermill": {
     "duration": 0.009305,
     "end_time": "2024-11-13T11:08:50.903256",
     "exception": false,
     "start_time": "2024-11-13T11:08:50.893951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you received an error response along the lines of `No user secrets exist for kernel id ...`, then you need to add your API key via `Add-ons`, `Secrets` **and** enable it.\n",
    "\n",
    "![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724424da",
   "metadata": {
    "id": "fegnGFpMS4AI",
    "papermill": {
     "duration": 0.008882,
     "end_time": "2024-11-13T11:08:50.921738",
     "exception": false,
     "start_time": "2024-11-13T11:08:50.912856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explore available models\n",
    "\n",
    "You will be using the [`embedContent`](https://ai.google.dev/api/embeddings#method:-models.embedcontent) API method to calculate embeddings in this guide. Find a model that supports it through the [`models.list`](https://ai.google.dev/api/models#method:-models.list) endpoint. You can also find more information about the embedding models on [the models page](https://ai.google.dev/gemini-api/docs/models/gemini#text-embedding).\n",
    "\n",
    "`text-embedding-004` is the most recent embedding model, so you will use it for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae19fa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:08:50.942997Z",
     "iopub.status.busy": "2024-11-13T11:08:50.941982Z",
     "iopub.status.idle": "2024-11-13T11:08:51.867119Z",
     "shell.execute_reply": "2024-11-13T11:08:51.865822Z"
    },
    "id": "Km5d13_FS2Q_",
    "papermill": {
     "duration": 0.938677,
     "end_time": "2024-11-13T11:08:51.869718",
     "exception": false,
     "start_time": "2024-11-13T11:08:50.931041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if \"embedContent\" in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c61ab",
   "metadata": {
    "id": "3XWKXoXwOGxS",
    "papermill": {
     "duration": 0.00908,
     "end_time": "2024-11-13T11:08:51.888146",
     "exception": false,
     "start_time": "2024-11-13T11:08:51.879066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data\n",
    "\n",
    "Here is a small set of documents you will use to create an embedding database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e43b01e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:08:51.909089Z",
     "iopub.status.busy": "2024-11-13T11:08:51.908277Z",
     "iopub.status.idle": "2024-11-13T11:08:51.915289Z",
     "shell.execute_reply": "2024-11-13T11:08:51.914150Z"
    },
    "id": "k8nsbhFJKmG-",
    "papermill": {
     "duration": 0.020014,
     "end_time": "2024-11-13T11:08:51.917526",
     "exception": false,
     "start_time": "2024-11-13T11:08:51.897512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DOCUMENT1 = \"Operating the Climate Control System  Your Googlecar has a climate control system that allows you to adjust the temperature and airflow in the car. To operate the climate control system, use the buttons and knobs located on the center console.  Temperature: The temperature knob controls the temperature inside the car. Turn the knob clockwise to increase the temperature or counterclockwise to decrease the temperature. Airflow: The airflow knob controls the amount of airflow inside the car. Turn the knob clockwise to increase the airflow or counterclockwise to decrease the airflow. Fan speed: The fan speed knob controls the speed of the fan. Turn the knob clockwise to increase the fan speed or counterclockwise to decrease the fan speed. Mode: The mode button allows you to select the desired mode. The available modes are: Auto: The car will automatically adjust the temperature and airflow to maintain a comfortable level. Cool: The car will blow cool air into the car. Heat: The car will blow warm air into the car. Defrost: The car will blow warm air onto the windshield to defrost it.\"\n",
    "DOCUMENT2 = 'Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.'\n",
    "DOCUMENT3 = \"Shifting Gears Your Googlecar has an automatic transmission. To shift gears, simply move the shift lever to the desired position.  Park: This position is used when you are parked. The wheels are locked and the car cannot move. Reverse: This position is used to back up. Neutral: This position is used when you are stopped at a light or in traffic. The car is not in gear and will not move unless you press the gas pedal. Drive: This position is used to drive forward. Low: This position is used for driving in snow or other slippery conditions.\"\n",
    "\n",
    "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4231f8e1",
   "metadata": {
    "id": "yDzxArLeOexD",
    "papermill": {
     "duration": 0.009055,
     "end_time": "2024-11-13T11:08:51.935735",
     "exception": false,
     "start_time": "2024-11-13T11:08:51.926680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating the embedding database with ChromaDB\n",
    "\n",
    "Create a [custom function](https://docs.trychroma.com/guides/embeddings#custom-embedding-functions) to generate embeddings with the Gemini API. In this task, you are implementing a retrieval system, so the `task_type` for generating the *document* embeddings is `retrieval_document`. Later, you will use `retrieval_query` for the *query* embeddings. Check out the [API reference](https://ai.google.dev/api/embeddings#v1beta.TaskType) for the full list of supported tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a964ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:08:51.956467Z",
     "iopub.status.busy": "2024-11-13T11:08:51.955759Z",
     "iopub.status.idle": "2024-11-13T11:08:53.261428Z",
     "shell.execute_reply": "2024-11-13T11:08:53.260541Z"
    },
    "id": "mF7Uu1kCQsT0",
    "papermill": {
     "duration": 1.319105,
     "end_time": "2024-11-13T11:08:53.264142",
     "exception": false,
     "start_time": "2024-11-13T11:08:51.945037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    # Specify whether to generate embeddings for documents, or queries\n",
    "    document_mode = True\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        else:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "\n",
    "        retry_policy = {\"retry\": retry.Retry(predicate=retry.if_transient_error)}\n",
    "\n",
    "        response = genai.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            content=input,\n",
    "            task_type=embedding_task,\n",
    "            request_options=retry_policy,\n",
    "        )\n",
    "        return response[\"embedding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ddd00",
   "metadata": {
    "id": "HrDWLyopPNBf",
    "papermill": {
     "duration": 0.009796,
     "end_time": "2024-11-13T11:08:53.283559",
     "exception": false,
     "start_time": "2024-11-13T11:08:53.273763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now create a [Chroma database client](https://docs.trychroma.com/getting-started) that uses the `GeminiEmbeddingFunction` and populate the database with the documents you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f4f44b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:08:53.304426Z",
     "iopub.status.busy": "2024-11-13T11:08:53.303850Z",
     "iopub.status.idle": "2024-11-13T11:08:54.056808Z",
     "shell.execute_reply": "2024-11-13T11:08:54.055899Z"
    },
    "id": "OITXgxZlLoXU",
    "papermill": {
     "duration": 0.766266,
     "end_time": "2024-11-13T11:08:54.059539",
     "exception": false,
     "start_time": "2024-11-13T11:08:53.293273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "DB_NAME = \"googlecardb\"\n",
    "embed_fn = GeminiEmbeddingFunction()\n",
    "embed_fn.document_mode = True\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "\n",
    "db.add(documents=documents, ids=[str(i) for i in range(len(documents))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c814a024",
   "metadata": {
    "id": "2QbwFgfXp-fL",
    "papermill": {
     "duration": 0.00914,
     "end_time": "2024-11-13T11:08:54.078038",
     "exception": false,
     "start_time": "2024-11-13T11:08:54.068898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Confirm that the data was inserted by looking at the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63169fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:08:54.098703Z",
     "iopub.status.busy": "2024-11-13T11:08:54.098280Z",
     "iopub.status.idle": "2024-11-13T11:08:54.109110Z",
     "shell.execute_reply": "2024-11-13T11:08:54.108051Z"
    },
    "id": "kQ9PHUL_l-hf",
    "papermill": {
     "duration": 0.024028,
     "end_time": "2024-11-13T11:08:54.111632",
     "exception": false,
     "start_time": "2024-11-13T11:08:54.087604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.count()\n",
    "# You can peek at the data too.\n",
    "# db.peek(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90973f60",
   "metadata": {
    "id": "Tu5zRErgsQ8u",
    "papermill": {
     "duration": 0.009116,
     "end_time": "2024-11-13T11:08:54.130124",
     "exception": false,
     "start_time": "2024-11-13T11:08:54.121008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Retrieval: Find relevant documents\n",
    "\n",
    "To search the Chroma database, call the `query` method. Note that you also switch to the `retrieval_query` mode of embedding generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4df68343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:08:54.151416Z",
     "iopub.status.busy": "2024-11-13T11:08:54.150693Z",
     "iopub.status.idle": "2024-11-13T11:08:54.559364Z",
     "shell.execute_reply": "2024-11-13T11:08:54.558341Z"
    },
    "id": "gQdJMbTSLtKE",
    "papermill": {
     "duration": 0.422193,
     "end_time": "2024-11-13T11:08:54.561879",
     "exception": false,
     "start_time": "2024-11-13T11:08:54.139686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch to query mode when generating embeddings.\n",
    "embed_fn.document_mode = False\n",
    "\n",
    "# Search the Chroma DB using the specified query.\n",
    "query = \"How do you use the touchscreen to play music?\"\n",
    "\n",
    "result = db.query(query_texts=[query], n_results=1)\n",
    "[[passage]] = result[\"documents\"]\n",
    "\n",
    "Markdown(passage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a06370",
   "metadata": {
    "id": "s8PNRMpOQkm5",
    "papermill": {
     "duration": 0.009841,
     "end_time": "2024-11-13T11:08:54.581673",
     "exception": false,
     "start_time": "2024-11-13T11:08:54.571832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Augmented generation: Answer the question\n",
    "\n",
    "Now that you have found a relevant passage from the set of documents (the *retrieval* step), you can now assemble a generation prompt to have the Gemini API *generate* a final answer. Note that in this example only a single passage was retrieved. In practice, especially when the size of your underlying data is large, you will want to retrieve more than one result and let the Gemini model determine what passages are relevant in answering the question. For this reason it's OK if some retrieved passages are not directly related to the question - this generation step should ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c947c03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:08:54.603023Z",
     "iopub.status.busy": "2024-11-13T11:08:54.602569Z",
     "iopub.status.idle": "2024-11-13T11:08:54.610120Z",
     "shell.execute_reply": "2024-11-13T11:08:54.609049Z"
    },
    "id": "b6_Y-GOymaXu",
    "papermill": {
     "duration": 0.021299,
     "end_time": "2024-11-13T11:08:54.612842",
     "exception": false,
     "start_time": "2024-11-13T11:08:54.591543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
      "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
      "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
      "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
      "\n",
      "QUESTION: How do you use the touchscreen to play music?\n",
      "PASSAGE: Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "query_oneline = query.replace(\"\\n\", \" \")\n",
    "\n",
    "# This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\n",
    "prompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
    "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
    "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
    "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
    "\n",
    "QUESTION: {query_oneline}\n",
    "PASSAGE: {passage_oneline}\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb618881",
   "metadata": {
    "id": "VRy6yXzcPxLB",
    "papermill": {
     "duration": 0.009625,
     "end_time": "2024-11-13T11:08:54.632396",
     "exception": false,
     "start_time": "2024-11-13T11:08:54.622771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now use the `generate_content` method to to generate an answer to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "127c1dff",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-11-13T11:08:54.655726Z",
     "iopub.status.busy": "2024-11-13T11:08:54.655290Z",
     "iopub.status.idle": "2024-11-13T11:09:10.506471Z",
     "shell.execute_reply": "2024-11-13T11:09:10.505205Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 15.866669,
     "end_time": "2024-11-13T11:09:10.509191",
     "exception": false,
     "start_time": "2024-11-13T11:08:54.642522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting g4f\r\n",
      "  Downloading g4f-0.3.3.3-py3-none-any.whl.metadata (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from g4f) (2.32.3)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from g4f) (3.9.5)\r\n",
      "Requirement already satisfied: brotli in /opt/conda/lib/python3.10/site-packages (from g4f) (1.1.0)\r\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from g4f) (3.20.0)\r\n",
      "Collecting curl-cffi>=0.6.2 (from g4f)\r\n",
      "  Downloading curl_cffi-0.7.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting cloudscraper (from g4f)\r\n",
      "  Downloading cloudscraper-1.2.71-py2.py3-none-any.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: cffi>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from curl-cffi>=0.6.2->g4f) (1.16.0)\r\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /opt/conda/lib/python3.10/site-packages (from curl-cffi>=0.6.2->g4f) (2024.8.30)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from curl-cffi>=0.6.2->g4f) (4.12.2)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->g4f) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->g4f) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->g4f) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->g4f) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->g4f) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->g4f) (4.0.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in /opt/conda/lib/python3.10/site-packages (from cloudscraper->g4f) (3.1.2)\r\n",
      "Requirement already satisfied: requests-toolbelt>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from cloudscraper->g4f) (0.10.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->g4f) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->g4f) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->g4f) (1.26.18)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12.0->curl-cffi>=0.6.2->g4f) (2.22)\r\n",
      "Downloading g4f-0.3.3.3-py3-none-any.whl (637 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.0/637.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading curl_cffi-0.7.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cloudscraper-1.2.71-py2.py3-none-any.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: curl-cffi, cloudscraper, g4f\r\n",
      "Successfully installed cloudscraper-1.2.71 curl-cffi-0.7.3 g4f-0.3.3.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install g4f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f77087",
   "metadata": {
    "papermill": {
     "duration": 0.011466,
     "end_time": "2024-11-13T11:09:10.532419",
     "exception": false,
     "start_time": "2024-11-13T11:09:10.520953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Used the below code When you Reach the google API Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58754b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:09:10.557887Z",
     "iopub.status.busy": "2024-11-13T11:09:10.556917Z",
     "iopub.status.idle": "2024-11-13T11:09:15.187712Z",
     "shell.execute_reply": "2024-11-13T11:09:15.186648Z"
    },
    "papermill": {
     "duration": 4.647271,
     "end_time": "2024-11-13T11:09:15.191018",
     "exception": false,
     "start_time": "2024-11-13T11:09:10.543747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Generated by BLACKBOX.AI, try unlimited chat https://www.blackbox.ai\n",
       "\n",
       "To play music using the touchscreen in your Googlecar, just tap on the \"Music\" icon displayed on the screen. This will allow you to access your favorite songs and playlists easily. It's as simple as touching the screen where the music option is located!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from g4f.client import Client\n",
    "from g4f.models import gpt_4o\n",
    "\n",
    "client = Client()\n",
    "response = client.chat.completions.create(\n",
    "    model=gpt_4o,\n",
    "    messages=[{'role':'user', 'content': prompt}]\n",
    ")\n",
    "\n",
    "response = response.choices[0].message.content\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1855680c",
   "metadata": {
    "papermill": {
     "duration": 0.011684,
     "end_time": "2024-11-13T11:09:15.215231",
     "exception": false,
     "start_time": "2024-11-13T11:09:15.203547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## i used Before the Google API That's the blow code not run Successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6faa415b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T11:09:15.241375Z",
     "iopub.status.busy": "2024-11-13T11:09:15.240335Z",
     "iopub.status.idle": "2024-11-13T11:09:16.483925Z",
     "shell.execute_reply": "2024-11-13T11:09:16.482036Z"
    },
    "id": "EwfyxFM6Giy9",
    "papermill": {
     "duration": 1.259545,
     "end_time": "2024-11-13T11:09:16.486369",
     "exception": true,
     "start_time": "2024-11-13T11:09:15.226824",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:676100395608'. [reason: \"RATE_LIMIT_EXCEEDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"consumer\"\n  value: \"projects/676100395608\"\n}\nmetadata {\n  key: \"quota_limit\"\n  value: \"GenerateContentRequestsPerMinutePerProjectPerRegion\"\n}\nmetadata {\n  key: \"quota_limit_value\"\n  value: \"0\"\n}\nmetadata {\n  key: \"quota_location\"\n  value: \"us-east7\"\n}\nmetadata {\n  key: \"quota_metric\"\n  value: \"generativelanguage.googleapis.com/generate_content_requests\"\n}\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, links {\n  description: \"Request a higher quota limit.\"\n  url: \"https://cloud.google.com/docs/quotas/help/request_increase\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-flash-latest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m Markdown(answer\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/client.py:267\u001b[0m, in \u001b[0;36m_ClientManager.make_client.<locals>.add_default_metadata_wrapper.<locals>.call\u001b[0;34m(metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;241m*\u001b[39margs, metadata\u001b[38;5;241m=\u001b[39m(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    266\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata)\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:676100395608'. [reason: \"RATE_LIMIT_EXCEEDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"consumer\"\n  value: \"projects/676100395608\"\n}\nmetadata {\n  key: \"quota_limit\"\n  value: \"GenerateContentRequestsPerMinutePerProjectPerRegion\"\n}\nmetadata {\n  key: \"quota_limit_value\"\n  value: \"0\"\n}\nmetadata {\n  key: \"quota_location\"\n  value: \"us-east7\"\n}\nmetadata {\n  key: \"quota_metric\"\n  value: \"generativelanguage.googleapis.com/generate_content_requests\"\n}\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, links {\n  description: \"Request a higher quota limit.\"\n  url: \"https://cloud.google.com/docs/quotas/help/request_increase\"\n}\n]"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d069785",
   "metadata": {
    "id": "ThTbjAJ7eGP5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Next steps\n",
    "\n",
    "Congrats on building a Retrieval-Augmented Generation app!\n",
    "\n",
    "To learn more about using embeddings in the Gemini API, check out the [Intro to embeddings](https://ai.google.dev/gemini-api/docs/embeddings) or to learn more fundamentals, study the [embeddings chapter](https://developers.google.com/machine-learning/crash-course/embeddings) of the Machine Learning Crash Course.\n",
    "\n",
    "For a hosted RAG system, check out the [Semantic Retrieval service](https://ai.google.dev/gemini-api/docs/semantic_retrieval) in the Gemini API. You can implement question-answering on your own documents in a single request, or host a database for even faster responses."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "day-2-document-q-a-with-rag.ipynb",
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 90.624534,
   "end_time": "2024-11-13T11:09:17.521990",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-13T11:07:46.897456",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
